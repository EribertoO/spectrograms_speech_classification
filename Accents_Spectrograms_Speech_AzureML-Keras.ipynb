{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Spectrograms of speech, identify accents using a CNN in Azure ML Services\n",
    "\n",
    "In this notebook we will develop a convolutional neural network using Keras with TensorFlow. The model will be trained and evaluated using Azure Machine Learnings Services, invoking API command for every one of the steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and configuring the Azure ML services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.48\n"
     ]
    }
   ],
   "source": [
    "import azureml\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Azure values in global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = os.getenv(\"SUBSCRIPTION_ID\", default=\"<SUBSCRIPTION_ID>\")\n",
    "resource_group = os.getenv(\"RESOURCE_GROUP\", default=\"<RESOURCE_GROUP>\")\n",
    "workspace_name = os.getenv(\"WORKSPACE_NAME\", default=\"<WORKSPACE_NAME>\")\n",
    "workspace_region = os.getenv(\"WORKSPACE_REGION\", default=\"<WORKSPACE_REGION>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize workspace\n",
    "Initialize a Workspace object from an existing workspace created in a previous training or it will be created if it does not exist. Then we create a config.json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n",
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code FF33HUK5P to authenticate.\n",
      "Interactive authentication successfully completed.\n",
      "Workspace configuration succeeded. Skip the workspace creation steps below\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "    # write the details of the workspace to a configuration file to the notebook library\n",
    "    ws.write_config()\n",
    "    print(\"Workspace configuration succeeded. Skip the workspace creation steps below\")\n",
    "except:\n",
    "    print(\"Workspace not accessible. Creating a new workspace below\")\n",
    "    # Create the workspace using the specified parameters\n",
    "    ws = Workspace.create(name = workspace_name,\n",
    "                      subscription_id = subscription_id,\n",
    "                      resource_group = resource_group, \n",
    "                      location = workspace_region,\n",
    "                      create_resource_group = True,\n",
    "                      exist_ok = True)\n",
    "    ws.get_details()\n",
    "\n",
    "    # write the details of the workspace to a configuration file to the notebook library\n",
    "    ws.write_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the values for the ML workspace \n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create compute resources for our  training experiments\n",
    "\n",
    "In this section we get compute resources where the model will be trained. We will search for an existing compute resource or if it does not exist we will create it. We can use a pre-created Virtual Machine, like a Azure Data Science Virtual Machine, or we can create a new compute resource indicating the type and computation power.\n",
    "\n",
    "To create a cluster, you need to specify a compute configuration that specifies the type of machine to be used and the scalability behaviors. Then you choose a name for the cluster that is unique within the workspace that can be used to address the cluster later. There are many types of compute resource, \"STANDARD_DS12_V2\", \"STANDARD_D4_V2\".\n",
    "\n",
    "From Microsoft docs:\n",
    "\n",
    "The cluster parameters are:\n",
    "\n",
    "vm_size - this describes the virtual machine type and size used in the cluster. All machines in the cluster are the same type. You can get the list of vm sizes available in your region by using the CLI command\n",
    "az vm list-skus -o tsv\n",
    "min_nodes - this sets the minimum size of the cluster. If you set the minimum to 0 the cluster will shut down all nodes while note in use. Setting this number to a value higher than 0 will allow for faster start-up times, but you will also be billed when the cluster is not in use.\n",
    "max_nodes - this sets the maximum size of the cluster. Setting this to a larger number allows for more concurrency and a greater distributed processing of scale-out jobs.\n",
    "To create a CPU cluster now, run the cell below. The autoscale settings mean that the cluster will scale down to 0 nodes when inactive and up to 4 nodes when busy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cpucluster\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your CPU cluster\n",
    "cpu_cluster_name = \"cpucluster\"\n",
    "#cpu_cluster_name = \"ML-VM-DSVM\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print(\"Found existing cpucluster\")\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating new cpucluster\")\n",
    "    \n",
    "    # Specify the configuration for the new cluster\n",
    "    # \"STANDARD_DS12_V2\" \"STANDARD_D4_V2\"\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D12_V2\",\n",
    "                                                           min_nodes=0,\n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # Create the cluster with the specified name and configuration\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "    \n",
    "    # Wait for the cluster to complete, show the output log\n",
    "    cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create/Open an Azure ML experiment\n",
    "\n",
    "Let's create an experiment named \"speech-cnn\". An experiment is a container, it will save our trainings, their metrics, their outputs,... Then we can analyze and compare our results on diferents arquitecture or parameters in the model. It will be our dairy during training and evaluating a ml model.\n",
    "\n",
    "We will create a folder to hold the training scripts. The script runs will be recorded under the experiment in Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "script_folder = './speech_cnn'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "\n",
    "exp = Experiment(workspace=ws, name='speech')\n",
    "print(\"Experiment: \",exp.name)\n",
    "print(\"Experiments in WS: \",exp.list(ws))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Spectrograms of Speech dataset to default datastore\n",
    "\n",
    "A datastore is a place where data can be stored that is then made accessible to a Run either by means of mounting or copying the data to the compute target. A datastore can either be backed by an Azure Blob Storage or and Azure File Share (ADLS will be supported in the future). \n",
    "For simple data handling, each workspace provides a default datastore that can be used, in case the data is not already in Blob Storage or File Share. We will use that default datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next step, we will upload the training and test dataset into the workspace's default datastore, which we will then later be mount on an AmlCompute cluster for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ./data/x_images_arrays_zip_1000.npz\n",
      "Uploading ./data/y_infected_labels_1000.npz\n",
      "Uploaded ./data/y_infected_labels_1000.npz, 1 files out of an estimated total of 2\n",
      "Uploaded ./data/x_images_arrays_zip_1000.npz, 2 files out of an estimated total of 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_b3879516944548e9b31877cc2fcb6b3c"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.upload(src_dir='./data', target_path='speech_specs', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get default Compute resource\n",
    "\n",
    "Now we get the compute resource, cpucluster, that we have created previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpucluster AmlCompute Succeeded\n"
     ]
    }
   ],
   "source": [
    "# We can list all the existing compute resources, identify wich one we would like to use.  \n",
    "compute_targets = ws.compute_targets\n",
    "for name, ct in compute_targets.items():\n",
    "    print(name, ct.type, ct.provisioning_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<azureml.core.compute.amlcompute.AmlComputeStatus object at 0x7f7214f2b160>\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "compute_target = ComputeTarget(ws, 'cpucluster')\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy the training files into the script folder\n",
    "\n",
    "The script folder should contain all the files necessary for the azure job to train the model. There will be a .py file where all the steps of the training proccess are defined: read the data, split the data, create the model, set the parameters, compile and fit the model, evaluate.\n",
    "\n",
    "So in the next code we will copy the .py file to the script folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./speech_cnn/train_cnn_gen.py'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# the training logic is in the keras_mnist.py file.\n",
    "shutil.copy('./train_cnn_gen.py', script_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./speech_cnn'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TensorFlow estimator & add Keras\n",
    "Next, we construct an azureml.train.dnn.TensorFlow estimator object, use the  compute target, and pass the mount-point of the datastore to the training code as a parameter. The TensorFlow estimator is providing a simple way of launching a TensorFlow training job on a compute target. It will automatically provide a docker image that has TensorFlow installed. In this case, we add keras package (for the Keras framework obviously), and matplotlib package for plotting a \"Loss vs. Accuracy\" chart and record it in run history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - framework_version is not specified, defaulting to version 1.13.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ds.path('speech_specs').as_download(),\n",
    "    '--batch-size': 32,\n",
    "    '--x_filename': 'x_speech_arrays_zip_4500.npz',\n",
    "    '--y_filename': 'y_speech_labels_4500.npz',\n",
    "    '--training_size': '4500',\n",
    "    '--n_epochs': 100\n",
    "}\n",
    "\n",
    "est = TensorFlow(source_directory=script_folder,\n",
    "                 script_params=script_params,\n",
    "                 compute_target=cpu_cluster, \n",
    "                 pip_packages=['keras', 'matplotlib'],\n",
    "                 conda_packages=['scikit-learn'],\n",
    "                 entry_script='train_cnn_gen.py', \n",
    "                 use_gpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit job to run\n",
    "Submit the estimator to the Azure ML experiment to kick off the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor the Run\n",
    "As the Run is executed, it will go through the following stages:\n",
    "\n",
    "Preparing: A docker image is created matching the Python environment specified by the TensorFlow estimator and it will be uploaded to the workspace's Azure Container Registry. This step will only happen once for each Python environment -- the container will then be cached for subsequent runs. Creating and uploading the image takes about 5 minutes. While the job is preparing, logs are streamed to the run history and can be viewed to monitor the progress of the image creation.\n",
    "\n",
    "Scaling: If the compute needs to be scaled up (i.e. the AmlCompute cluster requires more nodes to execute the run than currently available), the cluster will attempt to scale up in order to make the required amount of nodes available. Scaling typically takes about 5 minutes.\n",
    "\n",
    "Running: All scripts in the script folder are uploaded to the compute target, data stores are mounted/copied and the entry_script is executed. While the job is running, stdout and the ./logs folder are streamed to the run history and can be viewed to monitor the progress of the run.\n",
    "\n",
    "Post-Processing: The ./outputs folder of the run is copied over to the run history\n",
    "\n",
    "There are multiple ways to check the progress of a running job. We can use a Jupyter notebook widget.\n",
    "\n",
    "Note: The widget will automatically update ever 10-15 seconds, always showing you the most up-to-date information about the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792586cdbca44be4b11d733c010352f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=2, connect=3, read=3, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\",),)': /history/v1.0/subscriptions/83674078-c3fc-41e3-9cf6-93f29065e2a4/resourceGroups/CapstoneIA/providers/Microsoft.MachineLearningServices/workspaces/MalariaCNNKeras/experiments/speech/metrics?$filter=RunId%20eq%20speech_1564492233_9e23ac86&$continuationToken=%2BRID%3AflhwAIeVVQAe1C0AAACAAg%3D%3D%23RT%3A1%23TRC%3A50%23ISV%3A1%23FPC%3AAgi3AAAAAAoAALcAAAAACgAAtwAAAAAKAAASABIUAMAHAEEAwAdBAD4AMQAfAA%3D%3D\n"
     ]
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also periodically check the status of the run object, and navigate to Azure portal to monitor the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show some metrics from the experiment run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Loss': [1.0955833164708955,\n",
       "  1.075153040779011,\n",
       "  1.0529363508181722,\n",
       "  1.0343222243903463,\n",
       "  1.023221089166376,\n",
       "  0.9967844357939579,\n",
       "  0.9911308208388598,\n",
       "  0.9797448336810809,\n",
       "  0.9574432784666395,\n",
       "  0.9499125918999916,\n",
       "  0.9314793423152291,\n",
       "  0.9293175091123367,\n",
       "  0.9167442514222833,\n",
       "  0.9081856488112376,\n",
       "  0.8985620865372799,\n",
       "  0.8870494969757149,\n",
       "  0.8835849441220408,\n",
       "  0.8736895226576937,\n",
       "  0.8554565441448058,\n",
       "  0.8586099487249093,\n",
       "  0.8246951279618815,\n",
       "  0.8404530548728635,\n",
       "  0.8231880239841649,\n",
       "  0.8058394335310556,\n",
       "  0.8093994051351675,\n",
       "  0.7874928226385416,\n",
       "  0.7822506700396004,\n",
       "  0.7824323663797079,\n",
       "  0.7598635075872789,\n",
       "  0.756289806601178,\n",
       "  0.7387851864233145,\n",
       "  0.7325044742079594,\n",
       "  0.733957331811366,\n",
       "  0.7251220433701314,\n",
       "  0.7126694824128942,\n",
       "  0.7044057672333824,\n",
       "  0.7086608976526645,\n",
       "  0.6988241864961359,\n",
       "  0.6883164684334143,\n",
       "  0.6872050270371373,\n",
       "  0.6763843257865564,\n",
       "  0.658654801781402,\n",
       "  0.6673667163592283,\n",
       "  0.6511916895083782,\n",
       "  0.6381610899228152,\n",
       "  0.6463464455754233,\n",
       "  0.6395862925747585,\n",
       "  0.63255051620338,\n",
       "  0.6025958293756561,\n",
       "  0.5810066025887904,\n",
       "  0.5836931750378801,\n",
       "  0.5993555345877404,\n",
       "  0.5869799822969821,\n",
       "  0.568231106873585,\n",
       "  0.5961297570055376,\n",
       "  0.5602975256507172,\n",
       "  0.5495230421891661,\n",
       "  0.5482457886896861,\n",
       "  0.5554343106500771,\n",
       "  0.5370664751583151],\n",
       " 'Accuracy': [0.37137276785714285,\n",
       "  0.4105941704035874,\n",
       "  0.4349775784753363,\n",
       "  0.45347533632286996,\n",
       "  0.4644058295964126,\n",
       "  0.484585201793722,\n",
       "  0.4966367713004484,\n",
       "  0.5201793721973094,\n",
       "  0.5243834080717489,\n",
       "  0.531670403587444,\n",
       "  0.5456838565022422,\n",
       "  0.5462443946188341,\n",
       "  0.5627802690582959,\n",
       "  0.5622197309417041,\n",
       "  0.5672645739910314,\n",
       "  0.5714686098654709,\n",
       "  0.5891255605381166,\n",
       "  0.5863228699551569,\n",
       "  0.6045403587443946,\n",
       "  0.6003363228699552,\n",
       "  0.6334080717488789,\n",
       "  0.6006165919282511,\n",
       "  0.6196748878923767,\n",
       "  0.6266816143497758,\n",
       "  0.6258408071748879,\n",
       "  0.6434977578475336,\n",
       "  0.6429372197309418,\n",
       "  0.6415358744394619,\n",
       "  0.6614349775784754,\n",
       "  0.6547085201793722,\n",
       "  0.6676008968609866,\n",
       "  0.6676008968609866,\n",
       "  0.6681614349775785,\n",
       "  0.6771300448430493,\n",
       "  0.6844170403587444,\n",
       "  0.686939461883408,\n",
       "  0.688060538116592,\n",
       "  0.7006726457399103,\n",
       "  0.6964686098654709,\n",
       "  0.6984304932735426,\n",
       "  0.6989910313901345,\n",
       "  0.7096412556053812,\n",
       "  0.7093609865470852,\n",
       "  0.7242152466367713,\n",
       "  0.7216928251121076,\n",
       "  0.7208520179372198,\n",
       "  0.7250560538116592,\n",
       "  0.7317825112107623,\n",
       "  0.7485986547085202,\n",
       "  0.7533632286995515,\n",
       "  0.7558856502242153,\n",
       "  0.7435538116591929,\n",
       "  0.7485986547085202,\n",
       "  0.7668161434977578,\n",
       "  0.7457959641255605,\n",
       "  0.7558856502242153,\n",
       "  0.7721412556053812,\n",
       "  0.7690582959641256,\n",
       "  0.7614910313901345,\n",
       "  0.7698991031390134],\n",
       " 'Val_Loss': [1.0806221536227636,\n",
       "  1.0669315531493373,\n",
       "  1.0406410648491964,\n",
       "  1.0050983283508337,\n",
       "  1.0560726651734713,\n",
       "  1.0186259141949374,\n",
       "  0.9780308387496255,\n",
       "  1.0078301481082679,\n",
       "  0.9723585319290892,\n",
       "  1.0331485841833232,\n",
       "  1.0026159834063224,\n",
       "  0.9534704017867311,\n",
       "  0.98882634445811,\n",
       "  0.9637240707589109,\n",
       "  0.9442374877382124,\n",
       "  0.9407047288758414,\n",
       "  0.9510470109693171,\n",
       "  0.9112340214720183,\n",
       "  0.9264820560313868,\n",
       "  0.9452811918760601,\n",
       "  0.895401875938525,\n",
       "  0.8708254061817553,\n",
       "  0.926798457163943,\n",
       "  0.8564664849824313,\n",
       "  0.8183114346134606,\n",
       "  0.8495046253980062,\n",
       "  0.8150310793704394,\n",
       "  0.8209689924021086,\n",
       "  0.828800026594737,\n",
       "  0.8208792198217657,\n",
       "  0.810809816632952,\n",
       "  0.8244134013732655,\n",
       "  0.8318238413790197,\n",
       "  0.8895958214998245,\n",
       "  0.7519490205500114,\n",
       "  0.8163552092628901,\n",
       "  0.7894166804957048,\n",
       "  0.8683603933553377,\n",
       "  0.7273662686347961,\n",
       "  0.8113718636726078,\n",
       "  0.8745238204892172,\n",
       "  0.753127937111558,\n",
       "  0.7896925969557329,\n",
       "  0.8281861011776628,\n",
       "  0.7570197230035608,\n",
       "  0.7894168879304614,\n",
       "  0.7358556242935965,\n",
       "  0.7703647017478943,\n",
       "  0.764466207420997,\n",
       "  0.726403177069705,\n",
       "  0.7490368981680802,\n",
       "  0.7149555772970738,\n",
       "  0.663923547456139,\n",
       "  0.9365324313845931,\n",
       "  0.7095577802384299,\n",
       "  0.8003682529812224,\n",
       "  0.7545450127295901,\n",
       "  0.7248243834270814,\n",
       "  0.7087856504406655,\n",
       "  0.8403091072751004],\n",
       " 'Val_Accuracy': [0.390625,\n",
       "  0.42105263157894735,\n",
       "  0.44258373205741625,\n",
       "  0.47607655502392343,\n",
       "  0.43301435406698563,\n",
       "  0.49282296650717705,\n",
       "  0.507177033492823,\n",
       "  0.4665071770334928,\n",
       "  0.5119617224880383,\n",
       "  0.49521531100478466,\n",
       "  0.44976076555023925,\n",
       "  0.5191387559808612,\n",
       "  0.5095693779904307,\n",
       "  0.5095693779904307,\n",
       "  0.5741626794258373,\n",
       "  0.5357142857142857,\n",
       "  0.5358851674641149,\n",
       "  0.5358851674641149,\n",
       "  0.5645933014354066,\n",
       "  0.5430622009569378,\n",
       "  0.5263157894736842,\n",
       "  0.5717703349282297,\n",
       "  0.5526315789473685,\n",
       "  0.583732057416268,\n",
       "  0.6100478468899522,\n",
       "  0.6052631578947368,\n",
       "  0.6124401913875598,\n",
       "  0.6004784688995215,\n",
       "  0.5956937799043063,\n",
       "  0.6172248803827751,\n",
       "  0.6473214285714286,\n",
       "  0.631578947368421,\n",
       "  0.6196172248803827,\n",
       "  0.5980861244019139,\n",
       "  0.645933014354067,\n",
       "  0.6339712918660287,\n",
       "  0.6507177033492823,\n",
       "  0.6220095693779905,\n",
       "  0.6626794258373205,\n",
       "  0.638755980861244,\n",
       "  0.5933014354066986,\n",
       "  0.6483253588516746,\n",
       "  0.638755980861244,\n",
       "  0.6339712918660287,\n",
       "  0.6602870813397129,\n",
       "  0.65625,\n",
       "  0.6985645933014354,\n",
       "  0.6435406698564593,\n",
       "  0.6602870813397129,\n",
       "  0.69377990430622,\n",
       "  0.6674641148325359,\n",
       "  0.6889952153110048,\n",
       "  0.7105263157894737,\n",
       "  0.645933014354067,\n",
       "  0.6650717703349283,\n",
       "  0.6842105263157895,\n",
       "  0.6961722488038278,\n",
       "  0.7009569377990431,\n",
       "  0.7177033492822966,\n",
       "  0.6698564593301436],\n",
       " 'Final test loss': 0.6962542746748243,\n",
       " 'Accuracy vs Loss': 'aml://artifactId/ExperimentRun/dcid.speech_1562236054_b51e2e73/Accuracy vs Loss_1562245417.png',\n",
       " 'Final test accuracy': 0.7321428571428571,\n",
       " 'Training size': 4500.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'speech_1562584118_2df48015',\n",
       " 'target': 'cpucluster',\n",
       " 'status': 'Running',\n",
       " 'startTimeUtc': '2019-07-08T11:12:53.863613Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'ContentSnapshotId': 'edac3eca-cfa8-4a4c-bd34-1cd41b45c850',\n",
       "  'AzureML.DerivedImageName': 'azureml/azureml_d11eca37f102303834454016a14b7700'},\n",
       " 'runDefinition': {'script': 'train_cnn_gen_large.py',\n",
       "  'arguments': ['--data-folder',\n",
       "   '$AZUREML_DATAREFERENCE_3983386c7b6245298bb9b4d5e56cbee3',\n",
       "   '--batch-size',\n",
       "   '32',\n",
       "   '--x_filename',\n",
       "   'x_speech_arrays_zip_4500.npz',\n",
       "   '--y_filename',\n",
       "   'y_speech_labels_4500.npz',\n",
       "   '--training_size',\n",
       "   '4500',\n",
       "   '--n_epochs',\n",
       "   '60'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'cpucluster',\n",
       "  'dataReferences': {'3983386c7b6245298bb9b4d5e56cbee3': {'dataStoreName': 'workspaceblobstore',\n",
       "    'mode': 'Download',\n",
       "    'pathOnDataStore': 'speech_specs',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment speech Environment',\n",
       "   'version': 'Autosave_2019-07-02T11:12:52Z_9071688c',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['keras',\n",
       "        'matplotlib',\n",
       "        'azureml-defaults',\n",
       "        'tensorflow==1.13.1',\n",
       "        'horovod==0.16.1']},\n",
       "      'scikit-learn'],\n",
       "     'channels': ['conda-forge']},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'enabled': True,\n",
       "    'sharedVolumes': True,\n",
       "    'gpuSupport': False,\n",
       "    'shmSize': '1g',\n",
       "    'arguments': [],\n",
       "    'baseImageRegistry': {'address': None,\n",
       "     'username': None,\n",
       "     'password': None}},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'vmPriority': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None},\n",
       " 'logFiles': {'azureml-logs/70_driver_log.txt': 'https://malariacstoragef30815895.blob.core.windows.net/azureml/ExperimentRun/dcid.speech_1562584118_2df48015/azureml-logs/70_driver_log.txt?sv=2018-03-28&sr=b&sig=hEo%2FI4HOmKRhaxJ6zFmoWv6moOKR43NTB0pdS1BfLls%3D&st=2019-07-08T11%3A06%3A05Z&se=2019-07-08T19%3A16%3A05Z&sp=r'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accuracy vs Loss.png',\n",
       " 'azureml-logs/55_batchai_execution.txt',\n",
       " 'azureml-logs/60_control_log.txt',\n",
       " 'azureml-logs/80_driver_log.txt',\n",
       " 'logs/azureml/azureml.log',\n",
       " 'outputs/model/model.h5',\n",
       " 'outputs/model/model.json']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
